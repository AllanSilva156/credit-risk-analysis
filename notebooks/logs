2023-12-30 22:58:53,913:INFO:PyCaret ClassificationExperiment
2023-12-30 22:58:53,913:INFO:Logging name: clf-default-name
2023-12-30 22:58:53,913:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-12-30 22:58:53,913:INFO:version 3.2.0
2023-12-30 22:58:53,913:INFO:Initializing setup()
2023-12-30 22:58:53,913:INFO:self.USI: 5717
2023-12-30 22:58:53,913:INFO:self._variable_keys: {'logging_param', '_available_plots', 'fold_generator', 'is_multiclass', 'pipeline', 'log_plots_param', 'exp_id', 'fix_imbalance', 'exp_name_log', '_ml_usecase', 'gpu_param', 'seed', 'idx', 'X', 'X_test', 'gpu_n_jobs_param', 'target_param', 'n_jobs_param', 'html_param', 'data', 'y_train', 'X_train', 'fold_shuffle_param', 'fold_groups_param', 'y_test', 'y', 'memory', 'USI'}
2023-12-30 22:58:53,923:INFO:Checking environment
2023-12-30 22:58:53,923:INFO:python_version: 3.10.9
2023-12-30 22:58:53,923:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2023-12-30 22:58:53,923:INFO:machine: AMD64
2023-12-30 22:58:53,923:INFO:platform: Windows-10-10.0.22621-SP0
2023-12-30 22:58:53,930:INFO:Memory: svmem(total=34240491520, available=20275982336, percent=40.8, used=13964509184, free=20275982336)
2023-12-30 22:58:53,930:INFO:Physical Core: 16
2023-12-30 22:58:53,930:INFO:Logical Core: 32
2023-12-30 22:58:53,930:INFO:Checking libraries
2023-12-30 22:58:53,930:INFO:System:
2023-12-30 22:58:53,930:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2023-12-30 22:58:53,930:INFO:executable: c:\Users\Állan\Desktop\risco_credito_analise\venv\Scripts\python.exe
2023-12-30 22:58:53,930:INFO:   machine: Windows-10-10.0.22621-SP0
2023-12-30 22:58:53,930:INFO:PyCaret required dependencies:
2023-12-30 22:58:53,982:INFO:                 pip: 23.3.2
2023-12-30 22:58:53,982:INFO:          setuptools: 65.5.0
2023-12-30 22:58:53,982:INFO:             pycaret: 3.2.0
2023-12-30 22:58:53,983:INFO:             IPython: 8.19.0
2023-12-30 22:58:53,983:INFO:          ipywidgets: 8.1.1
2023-12-30 22:58:53,983:INFO:                tqdm: 4.66.1
2023-12-30 22:58:53,983:INFO:               numpy: 1.25.2
2023-12-30 22:58:53,983:INFO:              pandas: 1.5.3
2023-12-30 22:58:53,983:INFO:              jinja2: 3.1.2
2023-12-30 22:58:53,983:INFO:               scipy: 1.10.1
2023-12-30 22:58:53,983:INFO:              joblib: 1.3.2
2023-12-30 22:58:53,983:INFO:             sklearn: 1.2.2
2023-12-30 22:58:53,983:INFO:                pyod: 1.1.2
2023-12-30 22:58:53,983:INFO:            imblearn: 0.11.0
2023-12-30 22:58:53,983:INFO:   category_encoders: 2.6.3
2023-12-30 22:58:53,983:INFO:            lightgbm: 4.2.0
2023-12-30 22:58:53,983:INFO:               numba: 0.58.1
2023-12-30 22:58:53,983:INFO:            requests: 2.31.0
2023-12-30 22:58:53,983:INFO:          matplotlib: 3.6.0
2023-12-30 22:58:53,983:INFO:          scikitplot: 0.3.7
2023-12-30 22:58:53,983:INFO:         yellowbrick: 1.5
2023-12-30 22:58:53,983:INFO:              plotly: 5.18.0
2023-12-30 22:58:53,983:INFO:    plotly-resampler: Not installed
2023-12-30 22:58:53,983:INFO:             kaleido: 0.2.1
2023-12-30 22:58:53,983:INFO:           schemdraw: 0.15
2023-12-30 22:58:53,983:INFO:         statsmodels: 0.14.1
2023-12-30 22:58:53,983:INFO:              sktime: 0.21.1
2023-12-30 22:58:53,983:INFO:               tbats: 1.1.3
2023-12-30 22:58:53,983:INFO:            pmdarima: 2.0.4
2023-12-30 22:58:53,983:INFO:              psutil: 5.9.7
2023-12-30 22:58:53,983:INFO:          markupsafe: 2.1.3
2023-12-30 22:58:53,983:INFO:             pickle5: Not installed
2023-12-30 22:58:53,983:INFO:         cloudpickle: 3.0.0
2023-12-30 22:58:53,983:INFO:         deprecation: 2.1.0
2023-12-30 22:58:53,983:INFO:              xxhash: 3.4.1
2023-12-30 22:58:53,983:INFO:           wurlitzer: Not installed
2023-12-30 22:58:53,983:INFO:PyCaret optional dependencies:
2023-12-30 22:58:53,991:INFO:                shap: 0.44.0
2023-12-30 22:58:53,991:INFO:           interpret: 0.5.0
2023-12-30 22:58:53,991:INFO:                umap: 0.5.5
2023-12-30 22:58:53,991:INFO:     ydata_profiling: 4.6.3
2023-12-30 22:58:53,991:INFO:  explainerdashboard: 0.4.5
2023-12-30 22:58:53,991:INFO:             autoviz: Not installed
2023-12-30 22:58:53,991:INFO:           fairlearn: 0.7.0
2023-12-30 22:58:53,991:INFO:          deepchecks: Not installed
2023-12-30 22:58:53,991:INFO:             xgboost: Not installed
2023-12-30 22:58:53,991:INFO:            catboost: Not installed
2023-12-30 22:58:53,991:INFO:              kmodes: Not installed
2023-12-30 22:58:53,991:INFO:             mlxtend: Not installed
2023-12-30 22:58:53,991:INFO:       statsforecast: Not installed
2023-12-30 22:58:53,991:INFO:        tune_sklearn: Not installed
2023-12-30 22:58:53,991:INFO:                 ray: Not installed
2023-12-30 22:58:53,991:INFO:            hyperopt: Not installed
2023-12-30 22:58:53,991:INFO:              optuna: Not installed
2023-12-30 22:58:53,991:INFO:               skopt: Not installed
2023-12-30 22:58:53,991:INFO:              mlflow: 2.9.2
2023-12-30 22:58:53,991:INFO:              gradio: Not installed
2023-12-30 22:58:53,991:INFO:             fastapi: Not installed
2023-12-30 22:58:53,991:INFO:             uvicorn: Not installed
2023-12-30 22:58:53,991:INFO:              m2cgen: Not installed
2023-12-30 22:58:53,991:INFO:           evidently: Not installed
2023-12-30 22:58:53,991:INFO:               fugue: Not installed
2023-12-30 22:58:53,991:INFO:           streamlit: 1.29.0
2023-12-30 22:58:53,991:INFO:             prophet: Not installed
2023-12-30 22:58:53,991:INFO:None
2023-12-30 22:58:53,991:INFO:Set up data.
2023-12-30 22:58:54,003:INFO:Set up folding strategy.
2023-12-30 22:58:54,003:INFO:Set up train/test split.
2023-12-30 22:58:54,011:INFO:Set up index.
2023-12-30 22:58:54,011:INFO:Assigning column types.
2023-12-30 22:58:54,013:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-12-30 22:58:54,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-12-30 22:58:54,045:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-30 22:58:54,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-12-30 22:58:54,099:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-30 22:58:54,118:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,118:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,118:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-12-30 22:58:54,149:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-30 22:58:54,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,200:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-30 22:58:54,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,220:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-12-30 22:58:54,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,322:INFO:Preparing preprocessing pipeline...
2023-12-30 22:58:54,323:INFO:Set up simple imputation.
2023-12-30 22:58:54,326:INFO:Set up encoding of ordinal features.
2023-12-30 22:58:54,328:INFO:Set up encoding of categorical features.
2023-12-30 22:58:54,328:INFO:Set up removing outliers.
2023-12-30 22:58:54,328:INFO:Set up feature normalization.
2023-12-30 22:58:54,328:INFO:Set up column name cleaning.
2023-12-30 22:58:54,446:INFO:Finished creating preprocessing pipeline.
2023-12-30 22:58:54,459:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LLAN~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missi...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=42,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-12-30 22:58:54,459:INFO:Creating final display dataframe.
2023-12-30 22:58:54,703:INFO:Setup _display_container:                     Description                 Value
0                    Session id                    42
1                        Target  Status do empréstimo
2                   Target type                Binary
3           Original data shape           (26064, 10)
4        Transformed data shape           (25021, 18)
5   Transformed train set shape           (19808, 18)
6    Transformed test set shape            (5213, 18)
7              Ordinal features                     1
8              Numeric features                     6
9          Categorical features                     3
10     Rows with missing values                 12.1%
11                   Preprocess                  True
12              Imputation type                simple
13           Numeric imputation                  mean
14       Categorical imputation                  mode
15     Maximum one-hot encoding                    15
16              Encoding method                  None
17              Remove outliers                  True
18           Outliers threshold                  0.05
19                    Normalize                  True
20             Normalize method                minmax
21               Fold Generator                 KFold
22                  Fold Number                     5
23                     CPU Jobs                    -1
24                      Use GPU                 False
25               Log Experiment                 False
26              Experiment Name      clf-default-name
27                          USI                  5717
2023-12-30 22:58:54,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-30 22:58:54,809:INFO:setup() successfully completed in 1.26s...............
2023-12-30 22:58:54,837:INFO:Initializing get_config()
2023-12-30 22:58:54,837:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, variable=X_train)
2023-12-30 22:58:54,837:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-12-30 22:58:54,838:WARNING:c:\Users\Állan\Desktop\risco_credito_analise\venv\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-12-30 22:58:54,844:INFO:Variable:  returned as        Idade  Renda anual Tipo residência  Tempo no emprego  \
12521     26     390320.0        HIPOTECA               2.0   
29994     38     185640.0         ALUGUEL               1.0   
20461     33     190400.0        HIPOTECA               3.0   
850       22     108528.0        HIPOTECA               0.0   
23500     28     299880.0        HIPOTECA               0.0   
...      ...          ...             ...               ...   
30841     44     115668.0         ALUGUEL               0.0   
32492     51     399840.0         ALUGUEL               7.0   
31796     36     690200.0        HIPOTECA               4.0   
9536      26     595000.0         ALUGUEL               0.0   
31149     45     159936.0         ALUGUEL               8.0   

      Intenção de empréstimo  Valor do empréstimo  Taxa de juros  \
12521                PESSOAL              21420.0          15.05   
29994               EDUCAÇÃO              23800.0          17.74   
20461               EDUCAÇÃO              42840.0          13.16   
850                 EDUCAÇÃO              14280.0           8.94   
23500               EDUCAÇÃO              23800.0          13.67   
...                      ...                  ...            ...   
30841           INVESTIMENTO              46410.0          16.77   
32492                REFORMA              57120.0           7.49   
31796                PESSOAL              23800.0           9.62   
9536                  MÉDICO              38080.0           9.63   
31149           INVESTIMENTO              53788.0          12.17   

      Histórico não pagamentos  Tempo histórico de crédito  
12521                        S                           4  
29994                        N                          17  
20461                        N                           5  
850                          N                           2  
23500                        S                           7  
...                        ...                         ...  
30841                        N                          15  
32492                        N                          23  
31796                        N                          16  
9536                         N                           3  
31149                        N                          11  

[20851 rows x 9 columns]
2023-12-30 22:58:54,844:INFO:get_config() successfully completed......................................
2023-12-30 22:58:54,844:INFO:Initializing get_config()
2023-12-30 22:58:54,844:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, variable=y_train)
2023-12-30 22:58:54,844:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2023-12-30 22:58:54,844:WARNING:c:\Users\Állan\Desktop\risco_credito_analise\venv\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-12-30 22:58:54,846:INFO:Variable:  returned as 12521    0
29994    1
20461    0
850      0
23500    0
        ..
30841    1
32492    0
31796    0
9536     0
31149    1
Name: Status do empréstimo, Length: 20851, dtype: int8
2023-12-30 22:58:54,846:INFO:get_config() successfully completed......................................
2023-12-30 22:58:54,846:INFO:Initializing get_config()
2023-12-30 22:58:54,846:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, variable=X_test)
2023-12-30 22:58:54,846:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2023-12-30 22:58:54,846:WARNING:c:\Users\Állan\Desktop\risco_credito_analise\venv\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-12-30 22:58:54,850:INFO:Variable:  returned as        Idade  Renda anual Tipo residência  Tempo no emprego  \
11498     25     328440.0        HIPOTECA               4.0   
10474     23     142800.0         ALUGUEL               3.0   
23580     33     161840.0         ALUGUEL               3.0   
25137     29     380800.0         PRÓPRIO               0.0   
14203     24     423640.0        HIPOTECA               1.0   
...      ...          ...             ...               ...   
18433     32     428400.0         ALUGUEL              11.0   
28267     32      90440.0         ALUGUEL               1.0   
18927     31     138040.0        HIPOTECA               6.0   
26168     29     461720.0         PRÓPRIO               3.0   
14965     25     571200.0        HIPOTECA               7.0   

      Intenção de empréstimo  Valor do empréstimo  Taxa de juros  \
11498               EDUCAÇÃO              21420.0          14.65   
10474                PESSOAL              47600.0          11.48   
23580           INVESTIMENTO              42840.0          14.17   
25137           INVESTIMENTO             114240.0          12.87   
14203           INVESTIMENTO             119000.0          15.65   
...                      ...                  ...            ...   
18433                PESSOAL              95200.0          13.22   
28267           INVESTIMENTO              39627.0           6.62   
18927                PESSOAL              23800.0          15.99   
26168           INVESTIMENTO              57120.0          11.83   
14965                 MÉDICO              69020.0           7.49   

      Histórico não pagamentos  Tempo histórico de crédito  
11498                        S                           2  
10474                        N                           4  
23580                        S                          10  
25137                        N                           9  
14203                        S                           4  
...                        ...                         ...  
18433                        S                           6  
28267                        N                          10  
18927                        N                           7  
26168                        N                           5  
14965                        N                           4  

[5213 rows x 9 columns]
2023-12-30 22:58:54,851:INFO:get_config() successfully completed......................................
2023-12-30 22:58:54,851:INFO:Initializing get_config()
2023-12-30 22:58:54,851:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, variable=y_test)
2023-12-30 22:58:54,851:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2023-12-30 22:58:54,851:WARNING:c:\Users\Állan\Desktop\risco_credito_analise\venv\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-12-30 22:58:54,852:INFO:Variable:  returned as 11498    1
10474    1
23580    1
25137    0
14203    1
        ..
18433    0
28267    1
18927    0
26168    0
14965    0
Name: Status do empréstimo, Length: 5213, dtype: int8
2023-12-30 22:58:54,852:INFO:get_config() successfully completed......................................
2023-12-30 22:58:54,956:INFO:Initializing compare_models()
2023-12-30 22:58:54,956:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-12-30 22:58:54,956:INFO:Checking exceptions
2023-12-30 22:58:54,960:INFO:Preparing display monitor
2023-12-30 22:58:54,977:INFO:Initializing Logistic Regression
2023-12-30 22:58:54,977:INFO:Total runtime is 0.0 minutes
2023-12-30 22:58:54,979:INFO:SubProcess create_model() called ==================================
2023-12-30 22:58:54,980:INFO:Initializing create_model()
2023-12-30 22:58:54,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:58:54,980:INFO:Checking exceptions
2023-12-30 22:58:54,980:INFO:Importing libraries
2023-12-30 22:58:54,980:INFO:Copying training dataset
2023-12-30 22:58:54,986:INFO:Defining folds
2023-12-30 22:58:54,986:INFO:Declaring metric variables
2023-12-30 22:58:54,988:INFO:Importing untrained model
2023-12-30 22:58:54,991:INFO:Logistic Regression Imported successfully
2023-12-30 22:58:54,995:INFO:Starting cross validation
2023-12-30 22:58:54,996:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:58:58,318:INFO:Calculating mean and std
2023-12-30 22:58:58,319:INFO:Creating metrics dataframe
2023-12-30 22:58:58,323:INFO:Uploading results into container
2023-12-30 22:58:58,323:INFO:Uploading model into container now
2023-12-30 22:58:58,324:INFO:_master_model_container: 1
2023-12-30 22:58:58,324:INFO:_display_container: 2
2023-12-30 22:58:58,325:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-12-30 22:58:58,325:INFO:create_model() successfully completed......................................
2023-12-30 22:58:58,477:INFO:SubProcess create_model() end ==================================
2023-12-30 22:58:58,478:INFO:Creating metrics dataframe
2023-12-30 22:58:58,484:INFO:Initializing K Neighbors Classifier
2023-12-30 22:58:58,484:INFO:Total runtime is 0.05844189723332723 minutes
2023-12-30 22:58:58,486:INFO:SubProcess create_model() called ==================================
2023-12-30 22:58:58,486:INFO:Initializing create_model()
2023-12-30 22:58:58,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:58:58,486:INFO:Checking exceptions
2023-12-30 22:58:58,486:INFO:Importing libraries
2023-12-30 22:58:58,486:INFO:Copying training dataset
2023-12-30 22:58:58,492:INFO:Defining folds
2023-12-30 22:58:58,492:INFO:Declaring metric variables
2023-12-30 22:58:58,494:INFO:Importing untrained model
2023-12-30 22:58:58,496:INFO:K Neighbors Classifier Imported successfully
2023-12-30 22:58:58,500:INFO:Starting cross validation
2023-12-30 22:58:58,501:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:01,804:INFO:Calculating mean and std
2023-12-30 22:59:01,806:INFO:Creating metrics dataframe
2023-12-30 22:59:01,809:INFO:Uploading results into container
2023-12-30 22:59:01,810:INFO:Uploading model into container now
2023-12-30 22:59:01,810:INFO:_master_model_container: 2
2023-12-30 22:59:01,811:INFO:_display_container: 2
2023-12-30 22:59:01,811:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-12-30 22:59:01,811:INFO:create_model() successfully completed......................................
2023-12-30 22:59:01,980:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:01,980:INFO:Creating metrics dataframe
2023-12-30 22:59:01,987:INFO:Initializing Naive Bayes
2023-12-30 22:59:01,988:INFO:Total runtime is 0.11683606306711833 minutes
2023-12-30 22:59:01,990:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:01,990:INFO:Initializing create_model()
2023-12-30 22:59:01,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=nb, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:01,990:INFO:Checking exceptions
2023-12-30 22:59:01,990:INFO:Importing libraries
2023-12-30 22:59:01,991:INFO:Copying training dataset
2023-12-30 22:59:01,996:INFO:Defining folds
2023-12-30 22:59:01,996:INFO:Declaring metric variables
2023-12-30 22:59:01,999:INFO:Importing untrained model
2023-12-30 22:59:02,001:INFO:Naive Bayes Imported successfully
2023-12-30 22:59:02,006:INFO:Starting cross validation
2023-12-30 22:59:02,007:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:04,844:INFO:Calculating mean and std
2023-12-30 22:59:04,845:INFO:Creating metrics dataframe
2023-12-30 22:59:04,848:INFO:Uploading results into container
2023-12-30 22:59:04,848:INFO:Uploading model into container now
2023-12-30 22:59:04,849:INFO:_master_model_container: 3
2023-12-30 22:59:04,849:INFO:_display_container: 2
2023-12-30 22:59:04,849:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-12-30 22:59:04,849:INFO:create_model() successfully completed......................................
2023-12-30 22:59:05,013:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:05,013:INFO:Creating metrics dataframe
2023-12-30 22:59:05,020:INFO:Initializing Decision Tree Classifier
2023-12-30 22:59:05,020:INFO:Total runtime is 0.1673858046531677 minutes
2023-12-30 22:59:05,023:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:05,023:INFO:Initializing create_model()
2023-12-30 22:59:05,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:05,024:INFO:Checking exceptions
2023-12-30 22:59:05,024:INFO:Importing libraries
2023-12-30 22:59:05,024:INFO:Copying training dataset
2023-12-30 22:59:05,028:INFO:Defining folds
2023-12-30 22:59:05,029:INFO:Declaring metric variables
2023-12-30 22:59:05,031:INFO:Importing untrained model
2023-12-30 22:59:05,034:INFO:Decision Tree Classifier Imported successfully
2023-12-30 22:59:05,037:INFO:Starting cross validation
2023-12-30 22:59:05,038:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:07,959:INFO:Calculating mean and std
2023-12-30 22:59:07,961:INFO:Creating metrics dataframe
2023-12-30 22:59:07,965:INFO:Uploading results into container
2023-12-30 22:59:07,966:INFO:Uploading model into container now
2023-12-30 22:59:07,966:INFO:_master_model_container: 4
2023-12-30 22:59:07,966:INFO:_display_container: 2
2023-12-30 22:59:07,967:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-12-30 22:59:07,967:INFO:create_model() successfully completed......................................
2023-12-30 22:59:08,174:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:08,174:INFO:Creating metrics dataframe
2023-12-30 22:59:08,182:INFO:Initializing SVM - Linear Kernel
2023-12-30 22:59:08,182:INFO:Total runtime is 0.2200850486755371 minutes
2023-12-30 22:59:08,185:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:08,185:INFO:Initializing create_model()
2023-12-30 22:59:08,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=svm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:08,185:INFO:Checking exceptions
2023-12-30 22:59:08,185:INFO:Importing libraries
2023-12-30 22:59:08,185:INFO:Copying training dataset
2023-12-30 22:59:08,191:INFO:Defining folds
2023-12-30 22:59:08,191:INFO:Declaring metric variables
2023-12-30 22:59:08,193:INFO:Importing untrained model
2023-12-30 22:59:08,196:INFO:SVM - Linear Kernel Imported successfully
2023-12-30 22:59:08,201:INFO:Starting cross validation
2023-12-30 22:59:08,202:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:11,137:INFO:Calculating mean and std
2023-12-30 22:59:11,139:INFO:Creating metrics dataframe
2023-12-30 22:59:11,142:INFO:Uploading results into container
2023-12-30 22:59:11,143:INFO:Uploading model into container now
2023-12-30 22:59:11,143:INFO:_master_model_container: 5
2023-12-30 22:59:11,143:INFO:_display_container: 2
2023-12-30 22:59:11,144:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-12-30 22:59:11,144:INFO:create_model() successfully completed......................................
2023-12-30 22:59:11,306:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:11,306:INFO:Creating metrics dataframe
2023-12-30 22:59:11,313:INFO:Initializing Ridge Classifier
2023-12-30 22:59:11,313:INFO:Total runtime is 0.27226670185724894 minutes
2023-12-30 22:59:11,316:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:11,316:INFO:Initializing create_model()
2023-12-30 22:59:11,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:11,316:INFO:Checking exceptions
2023-12-30 22:59:11,316:INFO:Importing libraries
2023-12-30 22:59:11,316:INFO:Copying training dataset
2023-12-30 22:59:11,321:INFO:Defining folds
2023-12-30 22:59:11,321:INFO:Declaring metric variables
2023-12-30 22:59:11,324:INFO:Importing untrained model
2023-12-30 22:59:11,326:INFO:Ridge Classifier Imported successfully
2023-12-30 22:59:11,330:INFO:Starting cross validation
2023-12-30 22:59:11,331:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:14,051:INFO:Calculating mean and std
2023-12-30 22:59:14,052:INFO:Creating metrics dataframe
2023-12-30 22:59:14,056:INFO:Uploading results into container
2023-12-30 22:59:14,056:INFO:Uploading model into container now
2023-12-30 22:59:14,057:INFO:_master_model_container: 6
2023-12-30 22:59:14,057:INFO:_display_container: 2
2023-12-30 22:59:14,057:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-12-30 22:59:14,057:INFO:create_model() successfully completed......................................
2023-12-30 22:59:14,219:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:14,219:INFO:Creating metrics dataframe
2023-12-30 22:59:14,226:INFO:Initializing Random Forest Classifier
2023-12-30 22:59:14,226:INFO:Total runtime is 0.3208129644393921 minutes
2023-12-30 22:59:14,228:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:14,229:INFO:Initializing create_model()
2023-12-30 22:59:14,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:14,229:INFO:Checking exceptions
2023-12-30 22:59:14,229:INFO:Importing libraries
2023-12-30 22:59:14,229:INFO:Copying training dataset
2023-12-30 22:59:14,234:INFO:Defining folds
2023-12-30 22:59:14,234:INFO:Declaring metric variables
2023-12-30 22:59:14,237:INFO:Importing untrained model
2023-12-30 22:59:14,239:INFO:Random Forest Classifier Imported successfully
2023-12-30 22:59:14,243:INFO:Starting cross validation
2023-12-30 22:59:14,244:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:17,291:INFO:Calculating mean and std
2023-12-30 22:59:17,292:INFO:Creating metrics dataframe
2023-12-30 22:59:17,296:INFO:Uploading results into container
2023-12-30 22:59:17,296:INFO:Uploading model into container now
2023-12-30 22:59:17,297:INFO:_master_model_container: 7
2023-12-30 22:59:17,297:INFO:_display_container: 2
2023-12-30 22:59:17,297:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-12-30 22:59:17,297:INFO:create_model() successfully completed......................................
2023-12-30 22:59:17,449:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:17,450:INFO:Creating metrics dataframe
2023-12-30 22:59:17,457:INFO:Initializing Quadratic Discriminant Analysis
2023-12-30 22:59:17,457:INFO:Total runtime is 0.37465395530064904 minutes
2023-12-30 22:59:17,459:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:17,459:INFO:Initializing create_model()
2023-12-30 22:59:17,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=qda, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:17,460:INFO:Checking exceptions
2023-12-30 22:59:17,460:INFO:Importing libraries
2023-12-30 22:59:17,460:INFO:Copying training dataset
2023-12-30 22:59:17,465:INFO:Defining folds
2023-12-30 22:59:17,465:INFO:Declaring metric variables
2023-12-30 22:59:17,467:INFO:Importing untrained model
2023-12-30 22:59:17,469:INFO:Quadratic Discriminant Analysis Imported successfully
2023-12-30 22:59:17,473:INFO:Starting cross validation
2023-12-30 22:59:17,475:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:18,578:INFO:Calculating mean and std
2023-12-30 22:59:18,579:INFO:Creating metrics dataframe
2023-12-30 22:59:18,582:INFO:Uploading results into container
2023-12-30 22:59:18,582:INFO:Uploading model into container now
2023-12-30 22:59:18,583:INFO:_master_model_container: 8
2023-12-30 22:59:18,583:INFO:_display_container: 2
2023-12-30 22:59:18,583:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-12-30 22:59:18,583:INFO:create_model() successfully completed......................................
2023-12-30 22:59:18,726:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:18,727:INFO:Creating metrics dataframe
2023-12-30 22:59:18,734:INFO:Initializing Ada Boost Classifier
2023-12-30 22:59:18,734:INFO:Total runtime is 0.3959477821985881 minutes
2023-12-30 22:59:18,736:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:18,737:INFO:Initializing create_model()
2023-12-30 22:59:18,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:18,737:INFO:Checking exceptions
2023-12-30 22:59:18,737:INFO:Importing libraries
2023-12-30 22:59:18,737:INFO:Copying training dataset
2023-12-30 22:59:18,742:INFO:Defining folds
2023-12-30 22:59:18,742:INFO:Declaring metric variables
2023-12-30 22:59:18,745:INFO:Importing untrained model
2023-12-30 22:59:18,747:INFO:Ada Boost Classifier Imported successfully
2023-12-30 22:59:18,751:INFO:Starting cross validation
2023-12-30 22:59:18,752:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:20,313:INFO:Calculating mean and std
2023-12-30 22:59:20,314:INFO:Creating metrics dataframe
2023-12-30 22:59:20,316:INFO:Uploading results into container
2023-12-30 22:59:20,317:INFO:Uploading model into container now
2023-12-30 22:59:20,317:INFO:_master_model_container: 9
2023-12-30 22:59:20,317:INFO:_display_container: 2
2023-12-30 22:59:20,317:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-12-30 22:59:20,317:INFO:create_model() successfully completed......................................
2023-12-30 22:59:20,451:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:20,451:INFO:Creating metrics dataframe
2023-12-30 22:59:20,459:INFO:Initializing Gradient Boosting Classifier
2023-12-30 22:59:20,460:INFO:Total runtime is 0.42470761934916185 minutes
2023-12-30 22:59:20,462:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:20,462:INFO:Initializing create_model()
2023-12-30 22:59:20,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=gbc, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:20,462:INFO:Checking exceptions
2023-12-30 22:59:20,462:INFO:Importing libraries
2023-12-30 22:59:20,462:INFO:Copying training dataset
2023-12-30 22:59:20,467:INFO:Defining folds
2023-12-30 22:59:20,467:INFO:Declaring metric variables
2023-12-30 22:59:20,469:INFO:Importing untrained model
2023-12-30 22:59:20,472:INFO:Gradient Boosting Classifier Imported successfully
2023-12-30 22:59:20,478:INFO:Starting cross validation
2023-12-30 22:59:20,479:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:22,838:INFO:Calculating mean and std
2023-12-30 22:59:22,839:INFO:Creating metrics dataframe
2023-12-30 22:59:22,842:INFO:Uploading results into container
2023-12-30 22:59:22,842:INFO:Uploading model into container now
2023-12-30 22:59:22,843:INFO:_master_model_container: 10
2023-12-30 22:59:22,843:INFO:_display_container: 2
2023-12-30 22:59:22,843:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-12-30 22:59:22,843:INFO:create_model() successfully completed......................................
2023-12-30 22:59:22,987:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:22,987:INFO:Creating metrics dataframe
2023-12-30 22:59:22,995:INFO:Initializing Linear Discriminant Analysis
2023-12-30 22:59:22,995:INFO:Total runtime is 0.46696803967158007 minutes
2023-12-30 22:59:22,998:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:22,998:INFO:Initializing create_model()
2023-12-30 22:59:22,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=lda, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:22,998:INFO:Checking exceptions
2023-12-30 22:59:22,998:INFO:Importing libraries
2023-12-30 22:59:22,998:INFO:Copying training dataset
2023-12-30 22:59:23,003:INFO:Defining folds
2023-12-30 22:59:23,003:INFO:Declaring metric variables
2023-12-30 22:59:23,005:INFO:Importing untrained model
2023-12-30 22:59:23,008:INFO:Linear Discriminant Analysis Imported successfully
2023-12-30 22:59:23,012:INFO:Starting cross validation
2023-12-30 22:59:23,013:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:24,109:INFO:Calculating mean and std
2023-12-30 22:59:24,110:INFO:Creating metrics dataframe
2023-12-30 22:59:24,112:INFO:Uploading results into container
2023-12-30 22:59:24,113:INFO:Uploading model into container now
2023-12-30 22:59:24,113:INFO:_master_model_container: 11
2023-12-30 22:59:24,113:INFO:_display_container: 2
2023-12-30 22:59:24,113:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-12-30 22:59:24,113:INFO:create_model() successfully completed......................................
2023-12-30 22:59:24,248:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:24,248:INFO:Creating metrics dataframe
2023-12-30 22:59:24,256:INFO:Initializing Extra Trees Classifier
2023-12-30 22:59:24,256:INFO:Total runtime is 0.4879856189092001 minutes
2023-12-30 22:59:24,258:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:24,259:INFO:Initializing create_model()
2023-12-30 22:59:24,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:24,259:INFO:Checking exceptions
2023-12-30 22:59:24,259:INFO:Importing libraries
2023-12-30 22:59:24,259:INFO:Copying training dataset
2023-12-30 22:59:24,264:INFO:Defining folds
2023-12-30 22:59:24,264:INFO:Declaring metric variables
2023-12-30 22:59:24,266:INFO:Importing untrained model
2023-12-30 22:59:24,268:INFO:Extra Trees Classifier Imported successfully
2023-12-30 22:59:24,272:INFO:Starting cross validation
2023-12-30 22:59:24,273:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:25,798:INFO:Calculating mean and std
2023-12-30 22:59:25,800:INFO:Creating metrics dataframe
2023-12-30 22:59:25,803:INFO:Uploading results into container
2023-12-30 22:59:25,803:INFO:Uploading model into container now
2023-12-30 22:59:25,803:INFO:_master_model_container: 12
2023-12-30 22:59:25,803:INFO:_display_container: 2
2023-12-30 22:59:25,804:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-12-30 22:59:25,804:INFO:create_model() successfully completed......................................
2023-12-30 22:59:25,947:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:25,947:INFO:Creating metrics dataframe
2023-12-30 22:59:25,955:INFO:Initializing Light Gradient Boosting Machine
2023-12-30 22:59:25,955:INFO:Total runtime is 0.5162980914115907 minutes
2023-12-30 22:59:25,957:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:25,958:INFO:Initializing create_model()
2023-12-30 22:59:25,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:25,958:INFO:Checking exceptions
2023-12-30 22:59:25,958:INFO:Importing libraries
2023-12-30 22:59:25,958:INFO:Copying training dataset
2023-12-30 22:59:25,966:INFO:Defining folds
2023-12-30 22:59:25,966:INFO:Declaring metric variables
2023-12-30 22:59:25,969:INFO:Importing untrained model
2023-12-30 22:59:25,971:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-30 22:59:25,975:INFO:Starting cross validation
2023-12-30 22:59:25,976:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:27,488:INFO:Calculating mean and std
2023-12-30 22:59:27,489:INFO:Creating metrics dataframe
2023-12-30 22:59:27,492:INFO:Uploading results into container
2023-12-30 22:59:27,493:INFO:Uploading model into container now
2023-12-30 22:59:27,493:INFO:_master_model_container: 13
2023-12-30 22:59:27,493:INFO:_display_container: 2
2023-12-30 22:59:27,494:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-30 22:59:27,494:INFO:create_model() successfully completed......................................
2023-12-30 22:59:27,654:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:27,654:INFO:Creating metrics dataframe
2023-12-30 22:59:27,663:INFO:Initializing Dummy Classifier
2023-12-30 22:59:27,663:INFO:Total runtime is 0.5447564959526063 minutes
2023-12-30 22:59:27,665:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:27,665:INFO:Initializing create_model()
2023-12-30 22:59:27,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D93FAC3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:27,665:INFO:Checking exceptions
2023-12-30 22:59:27,665:INFO:Importing libraries
2023-12-30 22:59:27,665:INFO:Copying training dataset
2023-12-30 22:59:27,670:INFO:Defining folds
2023-12-30 22:59:27,670:INFO:Declaring metric variables
2023-12-30 22:59:27,673:INFO:Importing untrained model
2023-12-30 22:59:27,676:INFO:Dummy Classifier Imported successfully
2023-12-30 22:59:27,680:INFO:Starting cross validation
2023-12-30 22:59:27,682:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:28,743:INFO:Calculating mean and std
2023-12-30 22:59:28,744:INFO:Creating metrics dataframe
2023-12-30 22:59:28,746:INFO:Uploading results into container
2023-12-30 22:59:28,747:INFO:Uploading model into container now
2023-12-30 22:59:28,747:INFO:_master_model_container: 14
2023-12-30 22:59:28,747:INFO:_display_container: 2
2023-12-30 22:59:28,747:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-12-30 22:59:28,747:INFO:create_model() successfully completed......................................
2023-12-30 22:59:28,908:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:28,908:INFO:Creating metrics dataframe
2023-12-30 22:59:28,922:INFO:Initializing create_model()
2023-12-30 22:59:28,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:28,923:INFO:Checking exceptions
2023-12-30 22:59:28,924:INFO:Importing libraries
2023-12-30 22:59:28,924:INFO:Copying training dataset
2023-12-30 22:59:28,928:INFO:Defining folds
2023-12-30 22:59:28,928:INFO:Declaring metric variables
2023-12-30 22:59:28,928:INFO:Importing untrained model
2023-12-30 22:59:28,928:INFO:Declaring custom model
2023-12-30 22:59:28,929:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-30 22:59:28,930:INFO:Cross validation set to False
2023-12-30 22:59:28,930:INFO:Fitting Model
2023-12-30 22:59:29,099:WARNING:c:\Users\Állan\Desktop\risco_credito_analise\venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-12-30 22:59:29,788:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:29,788:INFO:[LightGBM] [Info] Number of positive: 4333, number of negative: 15475
2023-12-30 22:59:29,788:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000673 seconds.
2023-12-30 22:59:29,788:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:29,788:INFO:[LightGBM] [Info] Total Bins 818
2023-12-30 22:59:29,789:INFO:[LightGBM] [Info] Number of data points in the train set: 19808, number of used features: 17
2023-12-30 22:59:29,789:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218750 -> initscore=-1.272966
2023-12-30 22:59:29,790:INFO:[LightGBM] [Info] Start training from score -1.272966
2023-12-30 22:59:29,897:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-30 22:59:29,897:INFO:create_model() successfully completed......................................
2023-12-30 22:59:30,090:INFO:_master_model_container: 14
2023-12-30 22:59:30,090:INFO:_display_container: 2
2023-12-30 22:59:30,090:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-30 22:59:30,091:INFO:compare_models() successfully completed......................................
2023-12-30 22:59:30,173:INFO:Initializing tune_model()
2023-12-30 22:59:30,173:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>)
2023-12-30 22:59:30,173:INFO:Checking exceptions
2023-12-30 22:59:30,185:INFO:Copying training dataset
2023-12-30 22:59:30,190:INFO:Checking base model
2023-12-30 22:59:30,190:INFO:Base model : Light Gradient Boosting Machine
2023-12-30 22:59:30,193:INFO:Declaring metric variables
2023-12-30 22:59:30,195:INFO:Defining Hyperparameters
2023-12-30 22:59:30,344:INFO:Tuning with n_jobs=-1
2023-12-30 22:59:30,344:INFO:Initializing RandomizedSearchCV
2023-12-30 22:59:44,696:INFO:best_params: {'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2023-12-30 22:59:44,697:INFO:Hyperparameter search completed
2023-12-30 22:59:44,697:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:44,698:INFO:Initializing create_model()
2023-12-30 22:59:44,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020D94AC21D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 5, 'reg_alpha': 0.001, 'num_leaves': 30, 'n_estimators': 100, 'min_split_gain': 0.6, 'min_child_samples': 6, 'learning_rate': 0.2, 'feature_fraction': 0.8, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2023-12-30 22:59:44,698:INFO:Checking exceptions
2023-12-30 22:59:44,698:INFO:Importing libraries
2023-12-30 22:59:44,699:INFO:Copying training dataset
2023-12-30 22:59:44,706:INFO:Defining folds
2023-12-30 22:59:44,706:INFO:Declaring metric variables
2023-12-30 22:59:44,710:INFO:Importing untrained model
2023-12-30 22:59:44,710:INFO:Declaring custom model
2023-12-30 22:59:44,713:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-30 22:59:44,719:INFO:Starting cross validation
2023-12-30 22:59:44,720:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:46,338:INFO:Calculating mean and std
2023-12-30 22:59:46,339:INFO:Creating metrics dataframe
2023-12-30 22:59:46,344:INFO:Finalizing model
2023-12-30 22:59:46,543:WARNING:c:\Users\Állan\Desktop\risco_credito_analise\venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-12-30 22:59:47,231:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-12-30 22:59:47,231:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2023-12-30 22:59:47,231:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-12-30 22:59:47,236:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:47,236:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-12-30 22:59:47,236:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2023-12-30 22:59:47,236:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-12-30 22:59:47,236:INFO:[LightGBM] [Info] Number of positive: 4333, number of negative: 15475
2023-12-30 22:59:47,236:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
2023-12-30 22:59:47,236:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:47,237:INFO:[LightGBM] [Info] Total Bins 818
2023-12-30 22:59:47,237:INFO:[LightGBM] [Info] Number of data points in the train set: 19808, number of used features: 17
2023-12-30 22:59:47,237:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218750 -> initscore=-1.272966
2023-12-30 22:59:47,237:INFO:[LightGBM] [Info] Start training from score -1.272966
2023-12-30 22:59:47,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-30 22:59:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-30 22:59:47,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-30 22:59:47,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-30 22:59:47,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-12-30 22:59:47,347:INFO:Uploading results into container
2023-12-30 22:59:47,347:INFO:Uploading model into container now
2023-12-30 22:59:47,348:INFO:_master_model_container: 15
2023-12-30 22:59:47,348:INFO:_display_container: 3
2023-12-30 22:59:47,348:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=100, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.001, reg_lambda=5, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-30 22:59:47,348:INFO:create_model() successfully completed......................................
2023-12-30 22:59:47,512:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:47,512:INFO:choose_better activated
2023-12-30 22:59:47,515:INFO:SubProcess create_model() called ==================================
2023-12-30 22:59:47,515:INFO:Initializing create_model()
2023-12-30 22:59:47,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:47,515:INFO:Checking exceptions
2023-12-30 22:59:47,517:INFO:Importing libraries
2023-12-30 22:59:47,517:INFO:Copying training dataset
2023-12-30 22:59:47,521:INFO:Defining folds
2023-12-30 22:59:47,522:INFO:Declaring metric variables
2023-12-30 22:59:47,522:INFO:Importing untrained model
2023-12-30 22:59:47,522:INFO:Declaring custom model
2023-12-30 22:59:47,522:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-30 22:59:47,522:INFO:Starting cross validation
2023-12-30 22:59:47,523:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:49,003:INFO:Calculating mean and std
2023-12-30 22:59:49,004:INFO:Creating metrics dataframe
2023-12-30 22:59:49,006:INFO:Finalizing model
2023-12-30 22:59:49,207:WARNING:c:\Users\Állan\Desktop\risco_credito_analise\venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-12-30 22:59:49,909:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:49,909:INFO:[LightGBM] [Info] Number of positive: 4333, number of negative: 15475
2023-12-30 22:59:49,910:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.
2023-12-30 22:59:49,910:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 22:59:49,910:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 22:59:49,910:INFO:[LightGBM] [Info] Total Bins 818
2023-12-30 22:59:49,910:INFO:[LightGBM] [Info] Number of data points in the train set: 19808, number of used features: 17
2023-12-30 22:59:49,911:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218750 -> initscore=-1.272966
2023-12-30 22:59:49,911:INFO:[LightGBM] [Info] Start training from score -1.272966
2023-12-30 22:59:50,045:INFO:Uploading results into container
2023-12-30 22:59:50,046:INFO:Uploading model into container now
2023-12-30 22:59:50,046:INFO:_master_model_container: 16
2023-12-30 22:59:50,046:INFO:_display_container: 4
2023-12-30 22:59:50,047:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-30 22:59:50,047:INFO:create_model() successfully completed......................................
2023-12-30 22:59:50,211:INFO:SubProcess create_model() end ==================================
2023-12-30 22:59:50,212:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.7826
2023-12-30 22:59:50,212:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=100, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.001, reg_lambda=5, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.781
2023-12-30 22:59:50,213:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-12-30 22:59:50,213:INFO:choose_better completed
2023-12-30 22:59:50,213:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-12-30 22:59:50,219:INFO:_master_model_container: 16
2023-12-30 22:59:50,220:INFO:_display_container: 3
2023-12-30 22:59:50,220:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-30 22:59:50,220:INFO:tune_model() successfully completed......................................
2023-12-30 22:59:50,509:INFO:Initializing create_model()
2023-12-30 22:59:50,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:50,509:INFO:Checking exceptions
2023-12-30 22:59:50,519:INFO:Importing libraries
2023-12-30 22:59:50,519:INFO:Copying training dataset
2023-12-30 22:59:50,525:INFO:Defining folds
2023-12-30 22:59:50,525:INFO:Declaring metric variables
2023-12-30 22:59:50,528:INFO:Importing untrained model
2023-12-30 22:59:50,528:INFO:Declaring custom model
2023-12-30 22:59:50,531:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-30 22:59:50,535:INFO:Starting cross validation
2023-12-30 22:59:50,537:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-12-30 22:59:52,027:INFO:Calculating mean and std
2023-12-30 22:59:52,029:INFO:Creating metrics dataframe
2023-12-30 22:59:52,034:INFO:Finalizing model
2023-12-30 22:59:52,237:WARNING:c:\Users\Állan\Desktop\risco_credito_analise\venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-12-30 22:59:52,961:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:52,962:INFO:[LightGBM] [Info] Number of positive: 4333, number of negative: 15475
2023-12-30 22:59:52,962:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
2023-12-30 22:59:52,962:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:52,962:INFO:[LightGBM] [Info] Total Bins 818
2023-12-30 22:59:52,962:INFO:[LightGBM] [Info] Number of data points in the train set: 19808, number of used features: 17
2023-12-30 22:59:52,962:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218750 -> initscore=-1.272966
2023-12-30 22:59:52,963:INFO:[LightGBM] [Info] Start training from score -1.272966
2023-12-30 22:59:53,067:INFO:Uploading results into container
2023-12-30 22:59:53,068:INFO:Uploading model into container now
2023-12-30 22:59:53,075:INFO:_master_model_container: 17
2023-12-30 22:59:53,075:INFO:_display_container: 4
2023-12-30 22:59:53,076:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-30 22:59:53,076:INFO:create_model() successfully completed......................................
2023-12-30 22:59:53,287:INFO:Initializing finalize_model()
2023-12-30 22:59:53,287:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-12-30 22:59:53,288:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-30 22:59:53,291:INFO:Initializing create_model()
2023-12-30 22:59:53,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2023-12-30 22:59:53,291:INFO:Checking exceptions
2023-12-30 22:59:53,292:INFO:Importing libraries
2023-12-30 22:59:53,292:INFO:Copying training dataset
2023-12-30 22:59:53,292:INFO:Defining folds
2023-12-30 22:59:53,292:INFO:Declaring metric variables
2023-12-30 22:59:53,293:INFO:Importing untrained model
2023-12-30 22:59:53,293:INFO:Declaring custom model
2023-12-30 22:59:53,293:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-30 22:59:53,294:INFO:Cross validation set to False
2023-12-30 22:59:53,294:INFO:Fitting Model
2023-12-30 22:59:53,511:WARNING:c:\Users\Állan\Desktop\risco_credito_analise\venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-12-30 22:59:54,406:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:54,406:INFO:[LightGBM] [Info] Number of positive: 5389, number of negative: 19371
2023-12-30 22:59:54,407:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.
2023-12-30 22:59:54,407:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:54,407:INFO:[LightGBM] [Info] Total Bins 815
2023-12-30 22:59:54,407:INFO:[LightGBM] [Info] Number of data points in the train set: 24760, number of used features: 17
2023-12-30 22:59:54,408:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217649 -> initscore=-1.279417
2023-12-30 22:59:54,408:INFO:[LightGBM] [Info] Start training from score -1.279417
2023-12-30 22:59:54,546:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='de...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-12-30 22:59:54,546:INFO:create_model() successfully completed......................................
2023-12-30 22:59:54,717:INFO:_master_model_container: 17
2023-12-30 22:59:54,717:INFO:_display_container: 4
2023-12-30 22:59:54,730:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='de...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-12-30 22:59:54,730:INFO:finalize_model() successfully completed......................................
2023-12-30 22:59:54,967:INFO:Initializing plot_model()
2023-12-30 22:59:54,967:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='de...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, system=True)
2023-12-30 22:59:54,967:INFO:Checking exceptions
2023-12-30 22:59:54,972:INFO:Preloading libraries
2023-12-30 22:59:54,979:INFO:Copying training dataset
2023-12-30 22:59:54,979:INFO:Plot type: confusion_matrix
2023-12-30 22:59:55,241:INFO:Fitting Model
2023-12-30 22:59:55,241:INFO:Scoring test/hold-out set
2023-12-30 22:59:55,341:INFO:Visual Rendered Successfully
2023-12-30 22:59:55,485:INFO:plot_model() successfully completed......................................
2023-12-30 22:59:55,531:INFO:Initializing plot_model()
2023-12-30 22:59:55,531:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='de...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, system=True)
2023-12-30 22:59:55,532:INFO:Checking exceptions
2023-12-30 22:59:55,537:INFO:Preloading libraries
2023-12-30 22:59:55,544:INFO:Copying training dataset
2023-12-30 22:59:55,545:INFO:Plot type: class_report
2023-12-30 22:59:55,799:INFO:Fitting Model
2023-12-30 22:59:55,800:INFO:Scoring test/hold-out set
2023-12-30 22:59:55,951:INFO:Visual Rendered Successfully
2023-12-30 22:59:56,101:INFO:plot_model() successfully completed......................................
2023-12-30 22:59:56,150:INFO:Initializing plot_model()
2023-12-30 22:59:56,150:INFO:plot_model(plot=threshold, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='de...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, system=True)
2023-12-30 22:59:56,151:INFO:Checking exceptions
2023-12-30 22:59:56,155:INFO:Preloading libraries
2023-12-30 22:59:56,163:INFO:Copying training dataset
2023-12-30 22:59:56,163:INFO:Plot type: threshold
2023-12-30 22:59:56,417:INFO:Fitting Model
2023-12-30 22:59:56,427:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:56,427:INFO:[LightGBM] [Info] Number of positive: 3910, number of negative: 13917
2023-12-30 22:59:56,428:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
2023-12-30 22:59:56,428:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:56,428:INFO:[LightGBM] [Info] Total Bins 815
2023-12-30 22:59:56,428:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:56,428:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219330 -> initscore=-1.269574
2023-12-30 22:59:56,428:INFO:[LightGBM] [Info] Start training from score -1.269574
2023-12-30 22:59:56,561:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:56,562:INFO:[LightGBM] [Info] Number of positive: 3912, number of negative: 13915
2023-12-30 22:59:56,562:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2023-12-30 22:59:56,562:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:56,562:INFO:[LightGBM] [Info] Total Bins 812
2023-12-30 22:59:56,562:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:56,562:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219442 -> initscore=-1.268919
2023-12-30 22:59:56,563:INFO:[LightGBM] [Info] Start training from score -1.268919
2023-12-30 22:59:56,696:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:56,696:INFO:[LightGBM] [Info] Number of positive: 3865, number of negative: 13962
2023-12-30 22:59:56,697:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
2023-12-30 22:59:56,697:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:56,697:INFO:[LightGBM] [Info] Total Bins 812
2023-12-30 22:59:56,697:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:56,697:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216806 -> initscore=-1.284378
2023-12-30 22:59:56,697:INFO:[LightGBM] [Info] Start training from score -1.284378
2023-12-30 22:59:56,836:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:56,836:INFO:[LightGBM] [Info] Number of positive: 3877, number of negative: 13950
2023-12-30 22:59:56,837:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2023-12-30 22:59:56,837:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:56,837:INFO:[LightGBM] [Info] Total Bins 814
2023-12-30 22:59:56,837:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:56,837:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217479 -> initscore=-1.280418
2023-12-30 22:59:56,838:INFO:[LightGBM] [Info] Start training from score -1.280418
2023-12-30 22:59:56,978:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:56,978:INFO:[LightGBM] [Info] Number of positive: 3936, number of negative: 13891
2023-12-30 22:59:56,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000191 seconds.
2023-12-30 22:59:56,979:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 22:59:56,979:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 22:59:56,979:INFO:[LightGBM] [Info] Total Bins 810
2023-12-30 22:59:56,979:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:56,980:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220789 -> initscore=-1.261076
2023-12-30 22:59:56,980:INFO:[LightGBM] [Info] Start training from score -1.261076
2023-12-30 22:59:57,145:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:57,146:INFO:[LightGBM] [Info] Number of positive: 3906, number of negative: 13921
2023-12-30 22:59:57,146:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2023-12-30 22:59:57,146:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:57,146:INFO:[LightGBM] [Info] Total Bins 809
2023-12-30 22:59:57,146:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:57,147:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219106 -> initscore=-1.270885
2023-12-30 22:59:57,147:INFO:[LightGBM] [Info] Start training from score -1.270885
2023-12-30 22:59:57,287:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:57,287:INFO:[LightGBM] [Info] Number of positive: 3892, number of negative: 13935
2023-12-30 22:59:57,288:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2023-12-30 22:59:57,288:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:57,288:INFO:[LightGBM] [Info] Total Bins 814
2023-12-30 22:59:57,288:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:57,288:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218321 -> initscore=-1.275480
2023-12-30 22:59:57,288:INFO:[LightGBM] [Info] Start training from score -1.275480
2023-12-30 22:59:57,422:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:57,422:INFO:[LightGBM] [Info] Number of positive: 3898, number of negative: 13929
2023-12-30 22:59:57,422:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.
2023-12-30 22:59:57,422:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 22:59:57,422:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 22:59:57,423:INFO:[LightGBM] [Info] Total Bins 808
2023-12-30 22:59:57,423:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:57,423:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218657 -> initscore=-1.273509
2023-12-30 22:59:57,423:INFO:[LightGBM] [Info] Start training from score -1.273509
2023-12-30 22:59:57,595:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:57,595:INFO:[LightGBM] [Info] Number of positive: 3890, number of negative: 13937
2023-12-30 22:59:57,596:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000440 seconds.
2023-12-30 22:59:57,596:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:57,596:INFO:[LightGBM] [Info] Total Bins 813
2023-12-30 22:59:57,596:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:57,596:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218208 -> initscore=-1.276138
2023-12-30 22:59:57,596:INFO:[LightGBM] [Info] Start training from score -1.276138
2023-12-30 22:59:57,729:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:57,730:INFO:[LightGBM] [Info] Number of positive: 3908, number of negative: 13919
2023-12-30 22:59:57,730:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2023-12-30 22:59:57,730:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:57,730:INFO:[LightGBM] [Info] Total Bins 812
2023-12-30 22:59:57,731:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:57,731:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219218 -> initscore=-1.270229
2023-12-30 22:59:57,731:INFO:[LightGBM] [Info] Start training from score -1.270229
2023-12-30 22:59:57,862:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:57,862:INFO:[LightGBM] [Info] Number of positive: 3860, number of negative: 13967
2023-12-30 22:59:57,863:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000435 seconds.
2023-12-30 22:59:57,863:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:57,863:INFO:[LightGBM] [Info] Total Bins 812
2023-12-30 22:59:57,863:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:57,863:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216525 -> initscore=-1.286030
2023-12-30 22:59:57,863:INFO:[LightGBM] [Info] Start training from score -1.286030
2023-12-30 22:59:57,996:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:57,997:INFO:[LightGBM] [Info] Number of positive: 3922, number of negative: 13905
2023-12-30 22:59:57,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.
2023-12-30 22:59:57,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 22:59:57,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 22:59:57,997:INFO:[LightGBM] [Info] Total Bins 811
2023-12-30 22:59:57,997:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:57,998:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220003 -> initscore=-1.265647
2023-12-30 22:59:57,998:INFO:[LightGBM] [Info] Start training from score -1.265647
2023-12-30 22:59:58,162:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:58,162:INFO:[LightGBM] [Info] Number of positive: 3923, number of negative: 13904
2023-12-30 22:59:58,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.
2023-12-30 22:59:58,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 22:59:58,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 22:59:58,163:INFO:[LightGBM] [Info] Total Bins 810
2023-12-30 22:59:58,163:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:58,163:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220059 -> initscore=-1.265320
2023-12-30 22:59:58,163:INFO:[LightGBM] [Info] Start training from score -1.265320
2023-12-30 22:59:58,335:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:58,335:INFO:[LightGBM] [Info] Number of positive: 3875, number of negative: 13952
2023-12-30 22:59:58,336:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000176 seconds.
2023-12-30 22:59:58,336:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 22:59:58,336:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 22:59:58,336:INFO:[LightGBM] [Info] Total Bins 816
2023-12-30 22:59:58,336:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:58,336:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217367 -> initscore=-1.281077
2023-12-30 22:59:58,336:INFO:[LightGBM] [Info] Start training from score -1.281077
2023-12-30 22:59:58,497:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:58,497:INFO:[LightGBM] [Info] Number of positive: 3887, number of negative: 13940
2023-12-30 22:59:58,498:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000218 seconds.
2023-12-30 22:59:58,498:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 22:59:58,498:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 22:59:58,498:INFO:[LightGBM] [Info] Total Bins 812
2023-12-30 22:59:58,498:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:58,498:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218040 -> initscore=-1.277125
2023-12-30 22:59:58,499:INFO:[LightGBM] [Info] Start training from score -1.277125
2023-12-30 22:59:58,667:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:58,668:INFO:[LightGBM] [Info] Number of positive: 3878, number of negative: 13949
2023-12-30 22:59:58,668:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2023-12-30 22:59:58,668:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:58,668:INFO:[LightGBM] [Info] Total Bins 812
2023-12-30 22:59:58,669:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:58,669:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217535 -> initscore=-1.280088
2023-12-30 22:59:58,669:INFO:[LightGBM] [Info] Start training from score -1.280088
2023-12-30 22:59:58,803:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:58,809:INFO:[LightGBM] [Info] Number of positive: 3891, number of negative: 13936
2023-12-30 22:59:58,810:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000205 seconds.
2023-12-30 22:59:58,810:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 22:59:58,810:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 22:59:58,810:INFO:[LightGBM] [Info] Total Bins 815
2023-12-30 22:59:58,810:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:58,810:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218264 -> initscore=-1.275809
2023-12-30 22:59:58,810:INFO:[LightGBM] [Info] Start training from score -1.275809
2023-12-30 22:59:58,985:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:58,986:INFO:[LightGBM] [Info] Number of positive: 3890, number of negative: 13937
2023-12-30 22:59:58,986:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.
2023-12-30 22:59:58,986:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:58,986:INFO:[LightGBM] [Info] Total Bins 811
2023-12-30 22:59:58,986:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:58,987:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218208 -> initscore=-1.276138
2023-12-30 22:59:58,987:INFO:[LightGBM] [Info] Start training from score -1.276138
2023-12-30 22:59:59,129:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:59,129:INFO:[LightGBM] [Info] Number of positive: 3880, number of negative: 13947
2023-12-30 22:59:59,130:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2023-12-30 22:59:59,130:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:59,130:INFO:[LightGBM] [Info] Total Bins 813
2023-12-30 22:59:59,130:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:59,130:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217647 -> initscore=-1.279429
2023-12-30 22:59:59,130:INFO:[LightGBM] [Info] Start training from score -1.279429
2023-12-30 22:59:59,260:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:59,261:INFO:[LightGBM] [Info] Number of positive: 3924, number of negative: 13903
2023-12-30 22:59:59,261:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000208 seconds.
2023-12-30 22:59:59,261:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 22:59:59,261:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 22:59:59,261:INFO:[LightGBM] [Info] Total Bins 814
2023-12-30 22:59:59,261:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:59,261:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220116 -> initscore=-1.264993
2023-12-30 22:59:59,262:INFO:[LightGBM] [Info] Start training from score -1.264993
2023-12-30 22:59:59,432:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:59,433:INFO:[LightGBM] [Info] Number of positive: 3935, number of negative: 13892
2023-12-30 22:59:59,433:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000185 seconds.
2023-12-30 22:59:59,433:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 22:59:59,433:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 22:59:59,433:INFO:[LightGBM] [Info] Total Bins 816
2023-12-30 22:59:59,433:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:59,433:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220733 -> initscore=-1.261402
2023-12-30 22:59:59,434:INFO:[LightGBM] [Info] Start training from score -1.261402
2023-12-30 22:59:59,601:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:59,601:INFO:[LightGBM] [Info] Number of positive: 3893, number of negative: 13934
2023-12-30 22:59:59,602:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2023-12-30 22:59:59,602:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:59,602:INFO:[LightGBM] [Info] Total Bins 814
2023-12-30 22:59:59,602:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:59,602:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218377 -> initscore=-1.275152
2023-12-30 22:59:59,602:INFO:[LightGBM] [Info] Start training from score -1.275152
2023-12-30 22:59:59,737:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:59,737:INFO:[LightGBM] [Info] Number of positive: 3896, number of negative: 13931
2023-12-30 22:59:59,738:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000173 seconds.
2023-12-30 22:59:59,738:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 22:59:59,738:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 22:59:59,738:INFO:[LightGBM] [Info] Total Bins 811
2023-12-30 22:59:59,738:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:59,738:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218545 -> initscore=-1.274166
2023-12-30 22:59:59,738:INFO:[LightGBM] [Info] Start training from score -1.274166
2023-12-30 22:59:59,906:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 22:59:59,906:INFO:[LightGBM] [Info] Number of positive: 3915, number of negative: 13912
2023-12-30 22:59:59,906:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.
2023-12-30 22:59:59,906:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 22:59:59,907:INFO:[LightGBM] [Info] Total Bins 819
2023-12-30 22:59:59,907:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 22:59:59,907:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219611 -> initscore=-1.267936
2023-12-30 22:59:59,907:INFO:[LightGBM] [Info] Start training from score -1.267936
2023-12-30 23:00:00,041:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:00,041:INFO:[LightGBM] [Info] Number of positive: 3909, number of negative: 13918
2023-12-30 23:00:00,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
2023-12-30 23:00:00,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:00,042:INFO:[LightGBM] [Info] Total Bins 814
2023-12-30 23:00:00,042:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:00,042:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219274 -> initscore=-1.269901
2023-12-30 23:00:00,042:INFO:[LightGBM] [Info] Start training from score -1.269901
2023-12-30 23:00:00,177:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:00,177:INFO:[LightGBM] [Info] Number of positive: 3872, number of negative: 13955
2023-12-30 23:00:00,178:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000181 seconds.
2023-12-30 23:00:00,178:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 23:00:00,178:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 23:00:00,178:INFO:[LightGBM] [Info] Total Bins 815
2023-12-30 23:00:00,178:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:00,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217199 -> initscore=-1.282067
2023-12-30 23:00:00,178:INFO:[LightGBM] [Info] Start training from score -1.282067
2023-12-30 23:00:00,350:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:00,350:INFO:[LightGBM] [Info] Number of positive: 3893, number of negative: 13934
2023-12-30 23:00:00,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000163 seconds.
2023-12-30 23:00:00,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 23:00:00,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 23:00:00,351:INFO:[LightGBM] [Info] Total Bins 810
2023-12-30 23:00:00,351:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:00,351:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218377 -> initscore=-1.275152
2023-12-30 23:00:00,351:INFO:[LightGBM] [Info] Start training from score -1.275152
2023-12-30 23:00:00,519:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:00,520:INFO:[LightGBM] [Info] Number of positive: 3894, number of negative: 13933
2023-12-30 23:00:00,520:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.
2023-12-30 23:00:00,520:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 23:00:00,520:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 23:00:00,520:INFO:[LightGBM] [Info] Total Bins 816
2023-12-30 23:00:00,520:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:00,521:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218433 -> initscore=-1.274823
2023-12-30 23:00:00,521:INFO:[LightGBM] [Info] Start training from score -1.274823
2023-12-30 23:00:00,691:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:00,691:INFO:[LightGBM] [Info] Number of positive: 3881, number of negative: 13946
2023-12-30 23:00:00,692:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000214 seconds.
2023-12-30 23:00:00,692:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 23:00:00,692:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 23:00:00,692:INFO:[LightGBM] [Info] Total Bins 814
2023-12-30 23:00:00,692:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:00,692:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217703 -> initscore=-1.279100
2023-12-30 23:00:00,692:INFO:[LightGBM] [Info] Start training from score -1.279100
2023-12-30 23:00:00,862:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:00,862:INFO:[LightGBM] [Info] Number of positive: 3892, number of negative: 13935
2023-12-30 23:00:00,863:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2023-12-30 23:00:00,863:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:00,863:INFO:[LightGBM] [Info] Total Bins 814
2023-12-30 23:00:00,863:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:00,863:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218321 -> initscore=-1.275480
2023-12-30 23:00:00,863:INFO:[LightGBM] [Info] Start training from score -1.275480
2023-12-30 23:00:00,997:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:00,997:INFO:[LightGBM] [Info] Number of positive: 3915, number of negative: 13912
2023-12-30 23:00:00,998:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.
2023-12-30 23:00:00,998:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:00,998:INFO:[LightGBM] [Info] Total Bins 815
2023-12-30 23:00:00,998:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:00,998:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219611 -> initscore=-1.267936
2023-12-30 23:00:00,998:INFO:[LightGBM] [Info] Start training from score -1.267936
2023-12-30 23:00:01,129:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:01,130:INFO:[LightGBM] [Info] Number of positive: 3886, number of negative: 13941
2023-12-30 23:00:01,130:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.
2023-12-30 23:00:01,130:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 23:00:01,130:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 23:00:01,130:INFO:[LightGBM] [Info] Total Bins 812
2023-12-30 23:00:01,130:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:01,130:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217984 -> initscore=-1.277454
2023-12-30 23:00:01,130:INFO:[LightGBM] [Info] Start training from score -1.277454
2023-12-30 23:00:01,294:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:01,294:INFO:[LightGBM] [Info] Number of positive: 3873, number of negative: 13954
2023-12-30 23:00:01,294:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000341 seconds.
2023-12-30 23:00:01,294:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:01,294:INFO:[LightGBM] [Info] Total Bins 808
2023-12-30 23:00:01,294:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:01,295:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217255 -> initscore=-1.281737
2023-12-30 23:00:01,295:INFO:[LightGBM] [Info] Start training from score -1.281737
2023-12-30 23:00:01,426:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:01,427:INFO:[LightGBM] [Info] Number of positive: 3895, number of negative: 13932
2023-12-30 23:00:01,427:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000192 seconds.
2023-12-30 23:00:01,427:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 23:00:01,427:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 23:00:01,427:INFO:[LightGBM] [Info] Total Bins 810
2023-12-30 23:00:01,427:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:01,428:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218489 -> initscore=-1.274495
2023-12-30 23:00:01,428:INFO:[LightGBM] [Info] Start training from score -1.274495
2023-12-30 23:00:01,592:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:01,593:INFO:[LightGBM] [Info] Number of positive: 3908, number of negative: 13919
2023-12-30 23:00:01,593:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2023-12-30 23:00:01,593:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:01,593:INFO:[LightGBM] [Info] Total Bins 814
2023-12-30 23:00:01,593:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:01,594:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219218 -> initscore=-1.270229
2023-12-30 23:00:01,594:INFO:[LightGBM] [Info] Start training from score -1.270229
2023-12-30 23:00:01,728:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:01,728:INFO:[LightGBM] [Info] Number of positive: 3927, number of negative: 13900
2023-12-30 23:00:01,728:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.
2023-12-30 23:00:01,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 23:00:01,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 23:00:01,728:INFO:[LightGBM] [Info] Total Bins 813
2023-12-30 23:00:01,729:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:01,729:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220284 -> initscore=-1.264013
2023-12-30 23:00:01,729:INFO:[LightGBM] [Info] Start training from score -1.264013
2023-12-30 23:00:01,895:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:01,896:INFO:[LightGBM] [Info] Number of positive: 3910, number of negative: 13917
2023-12-30 23:00:01,896:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2023-12-30 23:00:01,896:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:01,896:INFO:[LightGBM] [Info] Total Bins 811
2023-12-30 23:00:01,896:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:01,896:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219330 -> initscore=-1.269574
2023-12-30 23:00:01,897:INFO:[LightGBM] [Info] Start training from score -1.269574
2023-12-30 23:00:02,041:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:02,042:INFO:[LightGBM] [Info] Number of positive: 3888, number of negative: 13939
2023-12-30 23:00:02,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2023-12-30 23:00:02,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:02,042:INFO:[LightGBM] [Info] Total Bins 813
2023-12-30 23:00:02,042:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:02,043:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218096 -> initscore=-1.276796
2023-12-30 23:00:02,043:INFO:[LightGBM] [Info] Start training from score -1.276796
2023-12-30 23:00:02,186:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:02,186:INFO:[LightGBM] [Info] Number of positive: 3940, number of negative: 13887
2023-12-30 23:00:02,187:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.
2023-12-30 23:00:02,187:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:02,187:INFO:[LightGBM] [Info] Total Bins 813
2023-12-30 23:00:02,187:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:02,187:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221013 -> initscore=-1.259772
2023-12-30 23:00:02,187:INFO:[LightGBM] [Info] Start training from score -1.259772
2023-12-30 23:00:02,330:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:02,330:INFO:[LightGBM] [Info] Number of positive: 3919, number of negative: 13908
2023-12-30 23:00:02,331:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2023-12-30 23:00:02,331:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:02,331:INFO:[LightGBM] [Info] Total Bins 816
2023-12-30 23:00:02,331:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:02,331:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219835 -> initscore=-1.266628
2023-12-30 23:00:02,331:INFO:[LightGBM] [Info] Start training from score -1.266628
2023-12-30 23:00:02,465:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:02,465:INFO:[LightGBM] [Info] Number of positive: 3911, number of negative: 13916
2023-12-30 23:00:02,466:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2023-12-30 23:00:02,466:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:02,466:INFO:[LightGBM] [Info] Total Bins 814
2023-12-30 23:00:02,466:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:02,466:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219386 -> initscore=-1.269246
2023-12-30 23:00:02,466:INFO:[LightGBM] [Info] Start training from score -1.269246
2023-12-30 23:00:02,598:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:02,598:INFO:[LightGBM] [Info] Number of positive: 3866, number of negative: 13961
2023-12-30 23:00:02,599:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2023-12-30 23:00:02,599:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:02,599:INFO:[LightGBM] [Info] Total Bins 815
2023-12-30 23:00:02,599:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:02,600:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216862 -> initscore=-1.284047
2023-12-30 23:00:02,600:INFO:[LightGBM] [Info] Start training from score -1.284047
2023-12-30 23:00:02,731:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:02,732:INFO:[LightGBM] [Info] Number of positive: 3882, number of negative: 13945
2023-12-30 23:00:02,732:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.
2023-12-30 23:00:02,732:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:02,732:INFO:[LightGBM] [Info] Total Bins 813
2023-12-30 23:00:02,732:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:02,732:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217760 -> initscore=-1.278771
2023-12-30 23:00:02,732:INFO:[LightGBM] [Info] Start training from score -1.278771
2023-12-30 23:00:02,865:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:02,865:INFO:[LightGBM] [Info] Number of positive: 3906, number of negative: 13921
2023-12-30 23:00:02,866:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.
2023-12-30 23:00:02,866:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:02,866:INFO:[LightGBM] [Info] Total Bins 814
2023-12-30 23:00:02,866:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:02,866:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219106 -> initscore=-1.270885
2023-12-30 23:00:02,866:INFO:[LightGBM] [Info] Start training from score -1.270885
2023-12-30 23:00:03,005:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:03,005:INFO:[LightGBM] [Info] Number of positive: 3920, number of negative: 13907
2023-12-30 23:00:03,005:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2023-12-30 23:00:03,006:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:03,006:INFO:[LightGBM] [Info] Total Bins 811
2023-12-30 23:00:03,006:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:03,006:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219891 -> initscore=-1.266301
2023-12-30 23:00:03,006:INFO:[LightGBM] [Info] Start training from score -1.266301
2023-12-30 23:00:03,139:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:03,139:INFO:[LightGBM] [Info] Number of positive: 3909, number of negative: 13918
2023-12-30 23:00:03,140:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.
2023-12-30 23:00:03,140:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 23:00:03,140:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 23:00:03,140:INFO:[LightGBM] [Info] Total Bins 814
2023-12-30 23:00:03,140:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:03,140:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219274 -> initscore=-1.269901
2023-12-30 23:00:03,140:INFO:[LightGBM] [Info] Start training from score -1.269901
2023-12-30 23:00:03,304:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:03,305:INFO:[LightGBM] [Info] Number of positive: 3894, number of negative: 13933
2023-12-30 23:00:03,305:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000181 seconds.
2023-12-30 23:00:03,305:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 23:00:03,305:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 23:00:03,305:INFO:[LightGBM] [Info] Total Bins 815
2023-12-30 23:00:03,305:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:03,306:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218433 -> initscore=-1.274823
2023-12-30 23:00:03,306:INFO:[LightGBM] [Info] Start training from score -1.274823
2023-12-30 23:00:03,467:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:03,467:INFO:[LightGBM] [Info] Number of positive: 3881, number of negative: 13946
2023-12-30 23:00:03,468:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2023-12-30 23:00:03,468:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:03,468:INFO:[LightGBM] [Info] Total Bins 814
2023-12-30 23:00:03,468:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:03,468:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217703 -> initscore=-1.279100
2023-12-30 23:00:03,468:INFO:[LightGBM] [Info] Start training from score -1.279100
2023-12-30 23:00:03,602:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:03,602:INFO:[LightGBM] [Info] Number of positive: 3917, number of negative: 13910
2023-12-30 23:00:03,603:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.
2023-12-30 23:00:03,603:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-12-30 23:00:03,603:INFO:[LightGBM] [Info] Total Bins 813
2023-12-30 23:00:03,603:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:03,603:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.219723 -> initscore=-1.267282
2023-12-30 23:00:03,603:INFO:[LightGBM] [Info] Start training from score -1.267282
2023-12-30 23:00:03,733:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-12-30 23:00:03,734:INFO:[LightGBM] [Info] Number of positive: 3867, number of negative: 13960
2023-12-30 23:00:03,734:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.
2023-12-30 23:00:03,734:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-12-30 23:00:03,734:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-12-30 23:00:03,734:INFO:[LightGBM] [Info] Total Bins 816
2023-12-30 23:00:03,734:INFO:[LightGBM] [Info] Number of data points in the train set: 17827, number of used features: 17
2023-12-30 23:00:03,735:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216918 -> initscore=-1.283717
2023-12-30 23:00:03,735:INFO:[LightGBM] [Info] Start training from score -1.283717
2023-12-30 23:00:04,351:INFO:Scoring test/hold-out set
2023-12-30 23:00:04,569:INFO:Visual Rendered Successfully
2023-12-30 23:00:04,708:INFO:plot_model() successfully completed......................................
2023-12-30 23:00:04,755:INFO:Initializing plot_model()
2023-12-30 23:00:04,755:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='de...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, system=True)
2023-12-30 23:00:04,756:INFO:Checking exceptions
2023-12-30 23:00:04,761:INFO:Preloading libraries
2023-12-30 23:00:04,769:INFO:Copying training dataset
2023-12-30 23:00:04,769:INFO:Plot type: auc
2023-12-30 23:00:05,021:INFO:Fitting Model
2023-12-30 23:00:05,022:INFO:Scoring test/hold-out set
2023-12-30 23:00:05,162:INFO:Visual Rendered Successfully
2023-12-30 23:00:05,313:INFO:plot_model() successfully completed......................................
2023-12-30 23:00:05,358:INFO:Initializing plot_model()
2023-12-30 23:00:05,358:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='de...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, system=True)
2023-12-30 23:00:05,358:INFO:Checking exceptions
2023-12-30 23:00:05,363:INFO:Preloading libraries
2023-12-30 23:00:05,371:INFO:Copying training dataset
2023-12-30 23:00:05,371:INFO:Plot type: feature
2023-12-30 23:00:05,371:WARNING:No coef_ found. Trying feature_importances_
2023-12-30 23:00:05,556:INFO:Visual Rendered Successfully
2023-12-30 23:00:05,702:INFO:plot_model() successfully completed......................................
2023-12-30 23:00:05,744:INFO:Initializing plot_model()
2023-12-30 23:00:05,744:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='de...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, system=True)
2023-12-30 23:00:05,744:INFO:Checking exceptions
2023-12-30 23:00:05,749:INFO:Preloading libraries
2023-12-30 23:00:05,757:INFO:Copying training dataset
2023-12-30 23:00:05,757:INFO:Plot type: learning
2023-12-30 23:00:06,016:INFO:Fitting Model
2023-12-30 23:00:09,463:INFO:Visual Rendered Successfully
2023-12-30 23:00:09,619:INFO:plot_model() successfully completed......................................
2023-12-30 23:00:09,695:INFO:Initializing save_model()
2023-12-30 23:00:09,695:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='de...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=../pipelines/dataset completo_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\LLAN~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missi...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=42,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-12-30 23:00:09,695:INFO:Adding model into prep_pipe
2023-12-30 23:00:09,696:WARNING:Only Model saved as it was a pipeline.
2023-12-30 23:00:09,734:INFO:../pipelines/dataset completo_pipeline.pkl saved in current working directory
2023-12-30 23:00:09,752:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='de...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-12-30 23:00:09,752:INFO:save_model() successfully completed......................................
2023-12-30 23:00:10,029:INFO:Initializing load_model()
2023-12-30 23:00:10,030:INFO:load_model(model_name=../pipelines/dataset completo_pipeline, platform=None, authentication=None, verbose=True)
2023-12-30 23:00:10,120:INFO:Initializing predict_model()
2023-12-30 23:00:10,120:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020D9478EDD0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\LLAN~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Idade', 'Renda anual',
                                             'Tempo no emprego',
                                             'Valor do empréstimo',
                                             'Taxa de juros',
                                             'Tempo histórico de crédito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missi...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020D952D0C10>)
2023-12-30 23:00:10,120:INFO:Checking exceptions
2023-12-30 23:00:10,120:INFO:Preloading libraries
2023-12-30 23:00:10,122:INFO:Set up data.
2023-12-30 23:00:10,128:INFO:Set up index.
